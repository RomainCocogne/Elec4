{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PNS ELEC4 EIEL821 Spectral Analysis \n",
    "\n",
    "# Chapter 3: Parametric estimation\n",
    "\n",
    "This Jupyter notebook aims at studying parametric techniques for spectral analysis, with particular focus on **AR modeling**.\n",
    "\n",
    "\n",
    "## Model mismatch\n",
    "\n",
    "\n",
    "**[HAY96, p. 441]** The performance of parametric techniques strongly depends on the fitness of the model. If the assumed model is inappropriate for the process under analysis, the parametric approach will lead to inaccurate or misleading spectral estimates. To illustrate this phenomenon, let us first consider a stochastic process consisting of **two sinusoids in additive noise**:\n",
    "\n",
    "$$X(n) = 10\\sin(0.4\\pi n + \\phi_1) + 5\\sin(0.6\\pi n + \\phi_2) + \\nu(n)$$\n",
    "\n",
    "where $\\nu(n)$ is a zero-mean unit-variance white noise and random phases $\\phi_1$ and $\\phi_2$ are distributed uniformly in $[0, 2\\pi]$ rad.\n",
    "\n",
    "\n",
    "* Generate 50 realizations of $N = 64$ samples of process $X(n)$. Plot one realization.\n",
    "\n",
    "\n",
    "* Justify why an AR(4) model would be appropriate for this process. Determine the AR model coefficients by solving the Yule-Walker equations based on biased ACS estimates. Derive the AR spectral estimate (in dB) of each signal realization. Superimpose the 50 spectral realizations in the same figure, with $\\omega$ in the interval $[0, \\pi]$ rad/sample.\n",
    "\n",
    "\n",
    "* Compute the average spectral estimate and plot it (in dB) in a different figure. Compare the average with the theoretical PSD of the process considered in this exercise. Superimpose (in dB) the variance of the spectral realizations. Compute the average variance over the whole frequency range.\n",
    "\n",
    "\n",
    "* Repeat using the periodogram as spectral estimator. Compare.\n",
    "\n",
    "\n",
    "Now assume that the process under analysis is actually governed by the **MA(2) model**:\n",
    "\n",
    "$$X(n) = \\varepsilon(n) - \\varepsilon(n-2)$$\n",
    "\n",
    "with theoretical PSD given by\n",
    "\n",
    "$$S_X(\\omega) = \\left|1 - \\mathrm{e}^{-\\jmath 2\\omega}\\right|^2 = (1 - \\mathrm{e}^{-\\jmath 2\\omega})(1 - \\mathrm{e}^{\\jmath 2\\omega}) = 2 - 2\\cos(2\\omega).$$\n",
    "\n",
    "\n",
    "* Repeat the above exercise for 50 realizations of this MA(2) random process. Compare the theoretical PSD with the AR(4) and periodogram estimates. Conclude.\n",
    "\n",
    "\n",
    "*Hint:* For the spectral representations, sample the frequency axis in $N_\\mathrm{FFT} = 1024$ equally-spaced points in the interval $[0, 2\\pi]$ rad/sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import toeplitz\n",
    "\n",
    "pi = np.pi\n",
    "fft = np.fft.fft\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "def gen_twosin(w, R, N):\n",
    "# Generates R random realizations of two sinusoids in random noise\n",
    "#\n",
    "# -- Output\n",
    "# x[R, N] : R process realizations of N samples \n",
    "# \n",
    "# -- Input\n",
    "# w[2] : frequency of sinusoids (rad/sample): [w1, w2]\n",
    "# R    : number of realizations\n",
    "# N    : number of samples\n",
    "\n",
    "    # <TO BE COMPLETED>\n",
    "    # .\n",
    "    # .\n",
    "    # .\n",
    "    x = np.zeros((R, N))\n",
    "    n = np.arange(N)\n",
    "    A = [10, 5]\n",
    "    for i in range(R):\n",
    "        np.random.seed(i);\n",
    "        x[i, :] = A[0]*np.sin(w[0]*n+2*pi*np.random.random())+A[1]*np.sin(w[1]*n+2*pi*np.random.random())+np.random.randn(1, N)\n",
    "    return x\n",
    "\n",
    "# ======================================================================\n",
    "def gen_ma2(R, N):\n",
    "# Generates R random realizations of MA(2) process\n",
    "#\n",
    "# -- Output\n",
    "# x[R, N] : R process realizations of N samples \n",
    "# \n",
    "# -- Input\n",
    "# R    : number of realizations\n",
    "# N    : number of samples\n",
    "\n",
    "    # <TO BE COMPLETED>\n",
    "    # .\n",
    "    # .\n",
    "    # .\n",
    "    \n",
    "    return x\n",
    "\n",
    "# ======================================================================\n",
    "def plot_realization(x, info):\n",
    "# Plots one signal realization\n",
    "#\n",
    "# x[R, N] : R realizations of N-sample random process\n",
    "# info    : a string with information to show in plot title\n",
    "# x\n",
    "  \n",
    "    [R, N] = x.shape\n",
    "    \n",
    "    # plot one signal realization\n",
    "    xabsmax = np.max(abs(x))\n",
    "    fig = plt.figure(figsize = (10, 4))\n",
    "    fig.suptitle(info) #'A realization of random process X(t), N = ' + str(N) + ' samples')\n",
    "    plt.stem(range(N), x[1,:])\n",
    "    plt.xlabel(r'$t$')\n",
    "    plt.ylabel(r'$x(t)$') \n",
    "    plt.axis([-1, N, -1.1*xabsmax, 1.1*xabsmax])\n",
    "    plt.grid()\n",
    "    \n",
    "    return\n",
    "\n",
    "# ======================================================================\n",
    "def acs_estimates(x, max_lag):\n",
    "# Computes biased autocorrelation sequence (ACS) estimates for input\n",
    "# signal realization at given lags\n",
    "#\n",
    "# -- Output\n",
    "# r[R, max_lag+1] : biased ACS estimats at lags 0 to max_lag for each of \n",
    "#                   the R input signal realizations\n",
    "#\n",
    "# -- Input\n",
    "# x[R, N]      : input signal (R realizations; N samples per realization) \n",
    "# max_lag      : maximum time lag for which the ACS is to be estimated\n",
    "\n",
    "    # <TO BE COMPLETED>\n",
    "    # .\n",
    "    # .\n",
    "    # .\n",
    "    for k in range (max_lag):\n",
    "        c = np.zeros((R))\n",
    "        for t in range (k, N):\n",
    "            c+=x[:, t]*np.conjugate(x[:, t-k])\n",
    "        r[:, k] = c\n",
    "    r/=N\n",
    "    return r\n",
    "\n",
    "# ======================================================================\n",
    "def ar(x, p, Nfft, verbose = True):\n",
    "# Computes AR(p) spectral estimate of random process realizations\n",
    "#\n",
    "# -- Output\n",
    "# Sx[R, Nfft] : R realizations of spectral estimates over Nfft frequency points in [0, 2*pi] rad/sample\n",
    "# r[R, p+1]   : R realizations of ACS estimates, from lag 0 to p\n",
    "# sg2[R]      : innovation variance (modeling error) for each realization\n",
    "# \n",
    "# -- Input\n",
    "# x[R, N] : R realizations of N-sample random process\n",
    "# p       : AR model order\n",
    "# Nfft    : number of FFT points\n",
    "# verbose : if true, verbose operation\n",
    "      \n",
    "    # <TO BE COMPLETED>\n",
    "    # .\n",
    "    # .\n",
    "    # .\n",
    "    [R, N] = x.shape\n",
    "    Sx = np.zeros((R, Nfft))\n",
    "    sg2 = np.zeros((R, 1))\n",
    "    w = np.arange(0, 2*pi, 2*pi/Nfft)\n",
    "    r = acs_estimates(x, p)\n",
    "    for i in range(R):\n",
    "        Rx = toelplitz(r[i, :p])\n",
    "        rp = r[i, 1:p+1]\n",
    "        a = np.linalg(Rx, -rp)\n",
    "        sg2[i].r[i, 0] + np.dot(np.conjugate(rp), a)\n",
    "        expjw = np.exp(-1j*np.ma.outerproduct(np.arange(1, p+1), w))\n",
    "        Sx[i, :] = sg2[i]/abs(1+np.dot(a, expjw))**2\n",
    "    return Sx, r, sg2\n",
    "    \n",
    "\n",
    "# ======================================================================\n",
    "\n",
    "\n",
    "N = 64       # total length of signal\n",
    "R = 50       # number of realizations\n",
    "w1 = 0.4*pi\n",
    "w2 = 0.6*pi\n",
    "max_lag = 50\n",
    "p = 4        # AR model order\n",
    "Nfft = 1024  # FFT length\n",
    "\n",
    "x = gen_twosin([w1, w2], R, N)\n",
    "\n",
    "# <TO BE COMPLETED>\n",
    "# .\n",
    "# .\n",
    "# .\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral line splitting\n",
    "\n",
    "**[HAY96, p. 443]** An artifact that may be observed with the autocorrelation method is **spectral line splitting**. This artifact consists of the splitting of a single spectral peak into two (or more) well separate and distinct peaks. Typically, this phenomenon occurs when $X(n)$ is overmodeled, i.e., when the assumed value of $p$ is too large as compared with the actual value of $p$ of the underlying model.\n",
    "\n",
    "\n",
    "To illustrate this phenomenon, consider the **AR(2) process** given by the difference equation:\n",
    "\n",
    "$$\n",
    "X(n) = -0.9X(n - 2) + \\varepsilon(n)\n",
    "$$\n",
    "\n",
    "where $\\varepsilon(n)$ is a zero-mean unit-variance white noise (innovation process).\n",
    "\n",
    "\n",
    "* Generate 5 independent random realizations of $N = 64$ samples of this AR(2) process. \n",
    "\n",
    "\n",
    "* Repeat the experiment of the previous section assuming an AR(4) model, and then an AR(12) model. What can be observed?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "def gen_ar2(R, N):\n",
    "# Generates R random realizations of the AR(2) process\n",
    "#\n",
    "# -- Output\n",
    "# x[R, N] : R process realizations of N samples \n",
    "# \n",
    "# -- Input\n",
    "# R : number of realizations\n",
    "# N : number of samples\n",
    "\n",
    "    # <TO BE COMPLETED>\n",
    "    # .\n",
    "    # .\n",
    "    # .\n",
    "    \n",
    "    return x\n",
    "\n",
    "# ======================================================================\n",
    "\n",
    "R = 5   # number of realizations\n",
    "Sx_bounds = [-20, 50, -20, 50]\n",
    "\n",
    "x = gen_ar2(R, N) # generate random realizations of AR(2) process\n",
    "\n",
    "    # <TO BE COMPLETED>\n",
    "    # .\n",
    "    # .\n",
    "    # .\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model order selection\n",
    "\n",
    "**Akaike's information criterion (AIC)**, the **minimum description length (MDL)** criterion and Akaike's **final prediction error (FPE)** criterion are given, respectively, by:\n",
    "\n",
    "$$\\mathrm{AIC}(p) = N\\log \\sigma^2_\\varepsilon + 2p$$\n",
    "\n",
    "$$\\mathrm{MDL}(p) = N\\log \\sigma^2_\\varepsilon + (\\log N)p$$\n",
    "\n",
    "$$\\mathrm{FPE}(p) = \\sigma^2_\\varepsilon \\frac{N + p + 1}{N - p - 1}.$$\n",
    "\n",
    "\n",
    "\n",
    "* Consider the **AR(2) model** of the previous exercise. For the realizations of $N = 64$ samples, compute and plot the AIC, MDL and FPE criteria as a function of the assumed model order $p$ in the range $[1, 10]$. Estimate the modeling error as the average innovation variance over the available signal realizations. Compare the different model order selection methods. Do they confirm that $p = 2$ is the right order for this AR process?\n",
    "\n",
    "\n",
    "* Repeat for the **two sinusoids in additive noise** studied at the beginning of this notebook. Do the order selection criteria confirm that AR(4) is a suitable model for this process?\n",
    "\n",
    "\n",
    "* What about the selected order for the **MA(2) process**?\n",
    "\n",
    "\n",
    "* Justify the shape of the curves for the different criteria in each case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "def model_order(x, pmax, info):\n",
    "# Determines and plots model order selection criteria (AIC, MDL, FPE)\n",
    "#\n",
    "# -- Input\n",
    "# x[R, N] : input signal realizations\n",
    "# pmax    : maximum model order\n",
    "# info    : string with additional information for plots\n",
    "\n",
    "    # <TO BE COMPLETED>\n",
    "    # .\n",
    "    # .\n",
    "    # .\n",
    "    \n",
    "    return\n",
    "\n",
    "# ======================================================================\n",
    "\n",
    "\n",
    "pmax = 10\n",
    "\n",
    "x = gen_ar2(R, N)\n",
    "info = 'AR(2) process'\n",
    "model_order(x, pmax, info)\n",
    "\n",
    "x = gen_twosin([w1, w2], R, N)\n",
    "info = 'two sinusoids in additive noise'\n",
    "model_order(x, pmax, info)\n",
    "\n",
    "x = gen_ma2(R, N)\n",
    "info = 'MA(2) process'\n",
    "model_order(x, pmax, info)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
