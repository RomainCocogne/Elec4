{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PNS ELEC4 EIEL821 Spectral Analysis \n",
    "\n",
    "# Chapter 3: Parametric estimation - solutions\n",
    "\n",
    "This Jupyter notebook aims at studying parametric techniques for spectral analysis, with particular focus on **AR modeling**.\n",
    "\n",
    "\n",
    "## Model mismatch\n",
    "\n",
    "\n",
    "**[HAY96, p. 441]** The performance of parametric techniques strongly depends on the fitness of the model. If the assumed model is inappropriate for the process under analysis, the parametric approach will lead to inaccurate or misleading spectral estimates. To illustrate this phenomenon, let us first consider a stochastic process consisting of **two sinusoids in additive noise**:\n",
    "\n",
    "$$X(n) = 10\\sin(0.4\\pi n + \\phi_1) + 5\\sin(0.6\\pi n + \\phi_2) + \\nu(n)$$\n",
    "\n",
    "where $\\nu(n)$ is a zero-mean unit-variance white noise and random phases $\\phi_1$ and $\\phi_2$ are distributed uniformly in $[0, 2\\pi]$ rad.\n",
    "\n",
    "\n",
    "* Generate 50 realizations of $N = 64$ samples of process $X(n)$. Plot one realization.\n",
    "\n",
    "\n",
    "* Justify why an AR(4) model would be appropriate for this process. Determine the AR model coefficients by solving the Yule-Walker equations based on biased ACS estimates. Derive the AR spectral estimate (in dB) of each signal realization. Superimpose the 50 spectral realizations in the same figure, with $\\omega$ in the interval $[0, \\pi]$ rad/sample.\n",
    "\n",
    "\n",
    "* Compute the average spectral estimate and plot it (in dB) in a different figure. Compare the average with the theoretical PSD of the process considered in this exercise. Superimpose (in dB) the variance of the spectral realizations. Compute the average variance over the whole frequency range.\n",
    "\n",
    "\n",
    "* Repeat using the periodogram as spectral estimator. Compare.\n",
    "\n",
    "\n",
    "Now assume that the process under analysis is actually governed by the **MA(2) model**:\n",
    "\n",
    "$$X(n) = \\varepsilon(n) - \\varepsilon(n-2)$$\n",
    "\n",
    "with theoretical PSD given by\n",
    "\n",
    "$$S_X(\\omega) = \\left|1 - \\mathrm{e}^{-\\jmath 2\\omega}\\right|^2 = (1 - \\mathrm{e}^{-\\jmath 2\\omega})(1 - \\mathrm{e}^{\\jmath 2\\omega}) = 2 - 2\\cos(2\\omega).$$\n",
    "\n",
    "\n",
    "* Repeat the above exercise for 50 realizations of this MA(2) random process. Compare the theoretical PSD with the AR(4) and periodogram estimates. Conclude.\n",
    "\n",
    "\n",
    "*Hint:* For the spectral representations, sample the frequency axis in $N_\\mathrm{FFT} = 1024$ equally-spaced points in the interval $[0, 2\\pi]$ rad/sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import toeplitz\n",
    "\n",
    "pi = np.pi\n",
    "fft = np.fft.fft\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "def gen_twosin(w, R, N):\n",
    "# Generates R random realizations of two sinusoids in random noise\n",
    "#\n",
    "# -- Output\n",
    "# x[R, N] : R process realizations of N samples \n",
    "# \n",
    "# -- Input\n",
    "# w[2] : frequency of sinusoids (rad/sample): [w1, w2]\n",
    "# R    : number of realizations\n",
    "# N    : number of samples\n",
    "\n",
    "    print('===== Two sinusoids in noise ==========')\n",
    "    \n",
    "    # generate random realizations\n",
    "    x = np.zeros((R, N))\n",
    "    n = np.arange(N)\n",
    "\n",
    "    for i in range(R):\n",
    "        np.random.seed(i)\n",
    "        x[i, :] = 10*np.sin(w[0]*n + 2*pi*np.random.rand()) + 5*np.sin(w[1]*n + 2*pi*np.random.rand()) + np.random.randn(1, N)\n",
    "        \n",
    "    return x\n",
    "\n",
    "# ======================================================================\n",
    "def gen_ma2(R, N):\n",
    "# Generates R random realizations of MA(2) process\n",
    "#\n",
    "# -- Output\n",
    "# x[R, N] : R process realizations of N samples \n",
    "# \n",
    "# -- Input\n",
    "# R    : number of realizations\n",
    "# N    : number of samples\n",
    "\n",
    "    print('===== MA(2) process ==========')\n",
    "    \n",
    "    # generate random realizations\n",
    "    x = np.random.randn(R, N+2)   # x will actually be of size (R, N); add two columns to account for the\n",
    "                                  # two-sample delay\n",
    "    x = x[:, 2:] - x[:, :-2]      # x[n] = e[n] - e[n-2]\n",
    "    \n",
    "    return x\n",
    "\n",
    "# ======================================================================\n",
    "def plot_realization(x, info):\n",
    "# Plots one signal realization\n",
    "#\n",
    "# x[R, N] : R realizations of N-sample random process\n",
    "# info    : a string with information to show in plot title\n",
    "  \n",
    "    [R, N] = x.shape\n",
    "    \n",
    "    # plot one signal realization\n",
    "    xabsmax = np.max(abs(x))\n",
    "    fig = plt.figure(figsize = (10, 4))\n",
    "    fig.suptitle(info)\n",
    "    plt.stem(range(N), x[1,:])\n",
    "    plt.xlabel(r'$n$')\n",
    "    plt.ylabel(r'$x(n)$') \n",
    "    plt.axis([-1, N, -1.1*xabsmax, 1.1*xabsmax])\n",
    "    plt.grid()\n",
    "    \n",
    "    return\n",
    "\n",
    "# ======================================================================\n",
    "def acs_estimates(x, max_lag):\n",
    "# Computes biased autocorrelation sequence (ACS) estimates for input\n",
    "# signal realization at given lags\n",
    "#\n",
    "# -- Output\n",
    "# r[R, max_lag+1] : biased ACS estimats at lags 0 to max_lag for each of \n",
    "#                   the R input signal realizations\n",
    "#\n",
    "# -- Input\n",
    "# x[R, N]      : input signal (R realizations; N samples per realization) \n",
    "# max_lag      : maximum time lag for which the ACS is to be estimated\n",
    "\n",
    "    [R, N] = x.shape\n",
    "    r = np.zeros((R, max_lag + 1))\n",
    "    \n",
    "    for k in range(max_lag + 1):\n",
    "        c = np.zeros((R))\n",
    "        for n in range(k, N):\n",
    "            c += x[:, n]*np.conjugate(x[:, n - k])  # elementwise product in Python\n",
    "              \n",
    "        r[:, k] = c    \n",
    "    \n",
    "    r /= N   # biased ACS estimate -> use 'N - k' for unbiased estimate\n",
    "    \n",
    "    return r\n",
    "\n",
    "# ======================================================================\n",
    "def ar(x, p, Nfft, verbose = True):\n",
    "# Computes AR(p) spectral estimate of random process realizations\n",
    "#\n",
    "# -- Output\n",
    "# Sx[R, Nfft] : R realizations of spectral estimates over Nfft frequency points in [0, 2*pi] rad/sample\n",
    "# r[R, p+1]   : R realizations of ACS estimates, from lag 0 to p\n",
    "# sg2[R]      : innovation variance (modeling error) for each realization\n",
    "# \n",
    "# -- Input\n",
    "# x[R, N] : R realizations of N-sample random process\n",
    "# p       : AR model order\n",
    "# Nfft    : number of FFT points\n",
    "# verbose : if true, verbose operation\n",
    "      \n",
    "    [R, N] = x.shape\n",
    "    \n",
    "    Sx = np.zeros((R, Nfft))          # AR(p) spectral estimate for each realization\n",
    "    sg2 = np.zeros((R, 1))            # modeling error\n",
    "    w = np.arange(0, 2*pi, 2*pi/Nfft) # frequency axis\n",
    "\n",
    "    print('>>> AR(' + str(p) + ') spectral estimate with N = ' + str(N) + ' samples')\n",
    "    \n",
    "    # compute and plot ACS estimates\n",
    "    r = acs_estimates(x, p)   # max lag = AR model order\n",
    "    \n",
    "    if verbose:\n",
    "        info = 'ACS estimate of process X(n), N = ' + str(N) + ' samples'\n",
    "        plot_realization(r, info)\n",
    "  \n",
    "    for i in range(R):\n",
    "            # build autocorrelation matrix\n",
    "            Rx = toeplitz(r[i, :p])\n",
    "            \n",
    "            # build independent vector\n",
    "            rp = r[i, 1:p+1]\n",
    "            \n",
    "            # solve Yule-Walker equations\n",
    "            a = np.linalg.solve(Rx, -rp)\n",
    "            \n",
    "            # compute modeling error (innovation variance)\n",
    "            sg2[i] = r[i, 0] + np.dot(np.conjugate(rp), a)\n",
    "            \n",
    "            # compute parametric PSD estimate at given frequency points\n",
    "            expjw = np.exp(-1j*np.ma.outerproduct(np.arange(1, p+1), w)); # expjw[k, m] = exp(-j*(k+1)*m/Nfft)          \n",
    "            Sx[i, :] = sg2[i]/abs(1 + np.dot(a, expjw))**2\n",
    "     \n",
    "    if verbose:\n",
    "        print('- average modeling error = ', round(np.mean(sg2), 4))\n",
    "  \n",
    "    return Sx, r, sg2\n",
    "    \n",
    "# ======================================================================\n",
    "def periodogram(x, Nfft = 1024): \n",
    "# Computes periodogram of random process realizations\n",
    "#\n",
    "# -- Output\n",
    "# Sx[R, Nfft] : R realizations of spectral estimates over Nfft frequency points in [0, 2*pi] rad/sample\n",
    "#\n",
    "# -- Input\n",
    "# x[R, N] : R realizations of N-sample random process\n",
    "# Nfft    : number of FFT points\n",
    "    \n",
    "    [R, N] = x.shape\n",
    "    \n",
    "    print('>>> Periodogram with N = ' + str(N) + ' samples')\n",
    "  \n",
    "    # compute FFT of each realization\n",
    "    X = fft(x, Nfft, 1)     # note: axes start counting from 0\n",
    "\n",
    "    # compute periodogram\n",
    "    Sx = abs(X)**2/N\n",
    "    \n",
    "    return Sx\n",
    "    \n",
    "# ======================================================================\n",
    "# ======================================================================\n",
    "def blackman_tuckey(r, window, Nfft):  # < TO BE COMPLETED >\n",
    "# Computes Blackman-Tuckey's spectral estimate of random process realizations\n",
    "#\n",
    "# -- Output\n",
    "# Sx[R, Nfft] : R realizations of spectral estimates over Nfft frequency points in [0, 2*pi] rad/sample\n",
    "#\n",
    "# -- Input\n",
    "# r[R, N] : R realizations of autocorrelation sequence at lags 0 to N-1 \n",
    "# window  : lag window; size determines BT truncation length of the ACS: lags -M+1 to M-1\n",
    "# Nfft    : number of FFT points\n",
    "    \n",
    "    R = r.shape[0]\n",
    "   \n",
    "    M = int((window.shape[1] + 1)/2)\n",
    "    \n",
    "    Sx = np.zeros((R, Nfft))     # BT's spectral estimate for each realization\n",
    "    \n",
    "    for i in range(R):\n",
    "        # compute Blackman-Tuckey's estimate\n",
    "        Sx[i, :] = abs(fft(window*np.concatenate((r[i, M-1:0:-1], r[i, :M])), Nfft))  # use 'abs' to avoid potential residual imaginary values\n",
    "                       \n",
    "    return Sx\n",
    "\n",
    "# ======================================================================\n",
    "\n",
    "def spectral_bias_variance(Sx, Sx_bounds, info):\n",
    "# Computes and plots bias and variance of spectral estimate\n",
    "#\n",
    "# -- Output\n",
    "# w  : frequency points (rad/sample) where PSD is plotted\n",
    "#\n",
    "# -- Input\n",
    "# Sx[R, Nfft] : R realizations of spectral estimates over Nfft frequency points in [0, 2*pi] rad/sample\n",
    "# Sx_bounds = [realization_min, realization_max, average_min, average_max]: bounds for spectral representation (dB) \n",
    "# info : a string with additional information to appear in plots (number of segments, overlap, etc.)\n",
    "\n",
    "    [R, Nfft] = Sx.shape\n",
    "  \n",
    "    # plot PSD realizations\n",
    "    w = np.arange(Nfft/2)*2/Nfft  # sampled frequency axis (relative to pi)\n",
    "    fig = plt.figure(figsize = (12, 4))\n",
    "    fig.suptitle('Spectral estimate realizations, mean and variance of random process X(n) - ' + info)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    \n",
    "    for i in range(R):\n",
    "        plt.plot(w, 10*np.log10(Sx[i, :int(Nfft/2)])) \n",
    "    \n",
    "    plt.xlabel(r'$\\omega/\\pi$')\n",
    "    plt.ylabel(r'$S_X(\\omega)\\ (dB)$')\n",
    "    plt.axis([0, 1, Sx_bounds[0], Sx_bounds[1]])\n",
    "    plt.grid()\n",
    "\n",
    "    # compute average periodogram and variance\n",
    "    Sx_ave = np.mean(Sx, 0)\n",
    "    Sx_var = np.var(Sx, 0)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(w, 10*np.log10(Sx_ave[:int(Nfft/2)]))   \n",
    "    plt.plot(w, 10*np.log10(Sx_var[:int(Nfft/2)]))   \n",
    "    plt.xlabel(r'$\\omega/\\pi$')\n",
    "    plt.ylabel(r'$S_X(\\omega)\\ (dB)$')\n",
    "    plt.legend(('mean', 'variance'))\n",
    "    plt.axis([0, 1, Sx_bounds[2], Sx_bounds[3]])\n",
    "    plt.grid()\n",
    "\n",
    "    # average variance over all frequencies\n",
    "    print('- average variance over all frequencies =',\n",
    "                  round(10*np.log10(np.mean(Sx_var)), 2), 'dB')\n",
    "    print()\n",
    "    \n",
    "    return pi*w\n",
    "\n",
    "# ======================================================================\n",
    "\n",
    "\n",
    "N = 64       # total length of signal\n",
    "R = 50       # number of realizations\n",
    "w1 = 0.4*pi\n",
    "w2 = 0.6*pi\n",
    "max_lag = 50\n",
    "p = 4        # AR model order\n",
    "Nfft = 1024  # FFT length\n",
    "Sx_bounds = [-20, 50, -20, 50] # bounds for spectral representation (dB) [realization_min, realization_max, average_min, average_max]\n",
    "\n",
    "\n",
    "x = gen_twosin([w1, w2], R, N)\n",
    "\n",
    "# plot one signal realization\n",
    "info = 'A realization of two sinusoids in noise random process X(n), N = ' + str(N) + ' samples'\n",
    "plot_realization(x, info)\n",
    "\n",
    "# compute AR spectral estimates\n",
    "[Sx, r, sg2] = ar(x, p, Nfft)\n",
    "\n",
    "# compute and plot bias and variance\n",
    "info = 'AR(' + str(p) + ') model, N = ' + str(N) + ' samples'\n",
    "spectral_bias_variance(Sx, Sx_bounds, info)\n",
    "\n",
    "# repeat using the periodogram\n",
    "#Sx = periodogram(x, Nfft)\n",
    "    \n",
    "# compute and plot bias and variance\n",
    "info = 'Periodogram, N = ' + str(N) + ' samples'\n",
    "spectral_bias_variance(Sx, Sx_bounds, info)\n",
    "\n",
    "\n",
    "# compute Blackman-Tuckey's spectral estimates  < TO BE COMPLETED >\n",
    "#window = np.ones((1, 2*p+1))   # rectangular window\n",
    "#Sx = blackman_tuckey(r, window, Nfft)\n",
    "\n",
    "# compute and plot bias and variance\n",
    "#info = \"Blackman-Tuckey, \"+ str(2*p+1) + \"-point rectangular window\"\n",
    "#spectral_bias_variance(Sx, Sx_bounds, info)\n",
    "\n",
    "\n",
    "x = gen_ma2(R, N) # generate random realizations of MA(2) process\n",
    "\n",
    "# plot one signal realization\n",
    "info = 'A realization of MA(2) random process X(n), N = ' + str(N) + ' samples'\n",
    "plot_realization(x, info)\n",
    "\n",
    "# compute AR spectral estimates\n",
    "[Sx, r, sg2] = ar(x, p, Nfft)\n",
    "\n",
    "# compute and plot bias and variance\n",
    "Sx_bounds = [-20, 20, -20, 20]\n",
    "info = 'AR(' + str(p) + ') model, N = ' + str(N) + ' samples'\n",
    "w = spectral_bias_variance(Sx, Sx_bounds, info)\n",
    "\n",
    "# add actual PSD\n",
    "Sx_true = 2 - 2*np.cos(2*w)\n",
    "plt.plot(w/pi, 10*np.log10(Sx_true))  \n",
    "plt.legend(('mean', 'variance', 'true PSD'))\n",
    "  \n",
    "# repeat using the periodogram\n",
    "Sx = periodogram(x, Nfft)\n",
    "    \n",
    "# compute and plot bias and variance\n",
    "info = 'Periodogram, N = ' + str(N) + ' samples'\n",
    "spectral_bias_variance(Sx, Sx_bounds, info)\n",
    "\n",
    "# add actual PSD\n",
    "plt.plot(w/pi, 10*np.log10(Sx_true))  \n",
    "plt.legend(('mean', 'variance', 'true PSD'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral line splitting\n",
    "\n",
    "**[HAY96, p. 443]** An artifact that may be observed with the autocorrelation method is **spectral line splitting**. This artifact consists of the splitting of a single spectral peak into two (or more) well separate and distinct peaks. Typically, this phenomenon occurs when $X(n)$ is overmodeled, i.e., when the assumed value of $p$ is too large as compared with the actual value of $p$ of the underlying model.\n",
    "\n",
    "\n",
    "To illustrate this phenomenon, consider the **AR(2) process** given by the difference equation:\n",
    "\n",
    "$$\n",
    "X(n) = -0.9X(n - 2) + \\varepsilon(n)\n",
    "$$\n",
    "\n",
    "where $\\varepsilon(n)$ is a zero-mean unit-variance white noise (innovation process).\n",
    "\n",
    "\n",
    "* Generate 5 independent random realizations of $N = 64$ samples of this AR(2) process. \n",
    "\n",
    "\n",
    "* Repeat the experiment of the previous section assuming an AR(4) model, and then an AR(12) model. What can be observed?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "def gen_ar2(R, N):\n",
    "# Generates R random realizations of the AR(2) process\n",
    "#\n",
    "# -- Output\n",
    "# x[R, N] : R process realizations of N samples \n",
    "# \n",
    "# -- Input\n",
    "# R : number of realizations\n",
    "# N : number of samples\n",
    "\n",
    "    print('===== AR(2) process ==========')\n",
    "    \n",
    "    # generate random realizations\n",
    "    e = np.random.randn(R, N+2)\n",
    "    x = np.zeros((R, N+2)) # x will actually be of size (R, N); \n",
    "                           # we add two columns to account for the two-sample delay\n",
    "\n",
    "    for n in range(2, N+2):\n",
    "        x[:, n] = -0.9*x[:, n-2] + e[:, n]\n",
    "    \n",
    "    x = x[:, 2:N+2]  # avoid initial transient interval\n",
    "    \n",
    "    return x\n",
    "\n",
    "# ======================================================================\n",
    "\n",
    "\n",
    "R = 5   # number of realizations\n",
    "Sx_bounds = [-20, 50, -20, 50]\n",
    "\n",
    "x = gen_ar2(R, N) # generate random realizations of AR(2) process\n",
    "\n",
    "# plot one signal realization\n",
    "info = 'A realization of AR(2) random process X(n), N = ' + str(N) + ' samples'\n",
    "plot_realization(x, info)\n",
    "\n",
    "for p in [4, 12]:\n",
    "\n",
    "    # compute AR spectral estimates\n",
    "    [Sx, r, sg2] = ar(x, p, Nfft)\n",
    "   \n",
    "    # compute and plot bias and variance\n",
    "    info = 'AR(' + str(p) + ') model, N = ' + str(N) + ' samples'\n",
    "    spectral_bias_variance(Sx, Sx_bounds, info)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model order selection\n",
    "\n",
    "**Akaike's information criterion (AIC)**, the **minimum description length (MDL)** criterion and Akaike's **final prediction error (FPE)** criterion are given, respectively, by:\n",
    "\n",
    "$$\\mathrm{AIC}(p) = N\\log \\sigma^2_\\varepsilon + 2p$$\n",
    "\n",
    "$$\\mathrm{MDL}(p) = N\\log \\sigma^2_\\varepsilon + (\\log N)p$$\n",
    "\n",
    "$$\\mathrm{FPE}(p) = \\sigma^2_\\varepsilon \\frac{N + p + 1}{N - p - 1}.$$\n",
    "\n",
    "\n",
    "\n",
    "* Consider the **AR(2) model** of the previous exercise. For the realizations of $N = 64$ samples, compute and plot the AIC, MDL and FPE criteria as a function of the assumed model order $p$ in the range $[1, 10]$. Estimate the modeling error as the average innovation variance over the available signal realizations. Compare the different model order selection methods. Do they confirm that $p = 2$ is the right order for this AR process?\n",
    "\n",
    "\n",
    "* Repeat for the **two sinusoids in additive noise** studied at the beginning of this notebook. Do the order selection criteria confirm that AR(4) is a suitable model for this process?\n",
    "\n",
    "\n",
    "* What about the selected order for the **MA(2) process**?\n",
    "\n",
    "\n",
    "* Justify the shape of the curves for the different criteria in each case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "def model_order(x, pmax, info):\n",
    "# Determines and plots model order selection criteria (AIC, MDL, FPE)\n",
    "#\n",
    "# -- Input\n",
    "# x[R, N] : input signal realizations\n",
    "# pmax    : maximum model order\n",
    "# info    : string with additional information for plots\n",
    "\n",
    "    sg2 = np.zeros(pmax)\n",
    "    \n",
    "    for p in range(1, pmax+1):\n",
    "        [Sx, r, sg2_current] = ar(x, p, 2, False) # just 2 FFT points suffice, since the PSD is not actually needed\n",
    "        sg2[p-1] = np.mean(sg2_current)  # average modeling error over realizations\n",
    "    \n",
    "    # compute model order selection criteria\n",
    "    C = np.zeros((3, pmax))\n",
    "    C[0, :] = N*np.log10(sg2) + 2*p \n",
    "    C[1, :] = N*np.log10(sg2) + np.log10(N)*p\n",
    "    C[2, :] = sg2*(N + p + 1)/(N - p - 1)\n",
    "\n",
    "    # plot criteria vs model order\n",
    "    fig = plt.figure(figsize = (10, 4))\n",
    "    fig.suptitle('Model order selection criteria - ' + info)\n",
    "    p = range(1, pmax+1)\n",
    "    \n",
    "    for i in range(3):\n",
    "        plt.plot(p, C[i,:])\n",
    "    \n",
    "    plt.xlabel('$p$')\n",
    "    plt.ylabel('C(p)') \n",
    "    plt.grid()\n",
    "    plt.legend(('AIC', 'MDL', 'FPE'))    \n",
    "\n",
    "    return\n",
    "\n",
    "# ======================================================================\n",
    "\n",
    "\n",
    "pmax = 10\n",
    "\n",
    "x = gen_ar2(R, N)\n",
    "info = 'AR(2) process, N = ' + str(N) + ' samples'\n",
    "model_order(x, pmax, info)\n",
    "\n",
    "x = gen_twosin([w1, w2], R, N)\n",
    "info = 'two sinusoids in additive noise, N = ' + str(N) + ' samples'\n",
    "model_order(x, pmax, info)\n",
    "\n",
    "x = gen_ma2(R, N)\n",
    "info = 'MA(2) process, N = ' + str(N) + ' samples'\n",
    "model_order(x, pmax, info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

